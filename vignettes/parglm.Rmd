---
title: "Introduction to the parglm package"
author: "Benjamin Christoffersen"
date: "`r Sys.Date()`"
output: rmarkdown::html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE, comment = "#>", fig.width = 7, fig.height = 4)
options(digits = 10)
```

The motivation for the `parglm` package is a parallel version of the `glm` 
function. It solves the iteratively re-weighted least squares using a QR 
decomposition with column pivoting with `DGEQP3` function from LAPACK. 
The computation is done in parallel as in the `bam` function in the `mgcv` package. The 
cost is an additional $O(Mp^2 + p^3)$ where $p$ is the number of 
coefficients and $M$ is the number chunks to be computed in parallel. 
The advantage is that you do not need to compile the package with 
an optimized BLAS or LAPACK which supports multithreading.

## Example of computation time

```{r set_params, echo = FALSE}
n <- 1000000L
p <- 50L
n_threads <- 18L
```

Below, we perform estimate a logistic regression with `r n` observations 
and `r p` covariates. We vary the number of cores being used with the
`nthreads` argument to `parglm.control`.

```{r sim}
#####
# simulate
n # number of observations
p # number of covariates
set.seed(68024947)
X <- matrix(rnorm(n * p, 1/p, 1/sqrt(p)), n, ncol = p)
df <- data.frame(y = 1/(1 + exp(-(rowSums(X) - 1))) > runif(n), X)
```


```{r run, cache = 1}
#####
# compute and measure time. Setup call to make
library(microbenchmark)
library(speedglm)
library(parglm)
cl <- list(
  quote(microbenchmark), 
  glm      = quote(glm     (y ~ ., binomial(), df)), 
  speedglm = quote(speedglm(y ~ ., family = binomial(), data = df)), 
  times = 5L)
cl <- c(
  cl, lapply(1:n_threads, function(i) bquote(parglm(
      y ~ ., binomial(), df, control = parglm.control(nthreads = .(i))))))
names(cl)[5:(5L + n_threads - 1L)] <- paste0("parglm.", 1:n_threads)
cl <- as.call(cl)
cl # the call we make

out <- eval(cl)
out # result from `microbenchmark`
```

The plot below shows median run times versus the number of cores. The dashed line 
is the median run time of `glm` and the dotted line is the median run time of 
`speedglm`. We could have used `glm.fit` and `parglm.fit`. This would make the 
relative difference bigger as both call e.g., `model.matrix` and `model.frame` which 
do take some time. To show this point, we first compute how much times this takes and 
then we make the plot. The continuous line is the computation time of `model.matrix` and 
`model.frame`.

```{r loadmicro, echo = FALSE}
library(microbenchmark) # in case the previous chunk is not run
```

```{r show_modmat_time, cache = 1}
modmat_time <- microbenchmark(
  modmat_time = {
    mf <- model.frame(y ~ ., df); model.matrix(terms(mf), mf)
  }, times = 10)
modmat_time # time taken by `model.matrix` and `model.frame`
```

```{r show_run_times}
par(mar = c(4.5, 4.5, .5, .5))
o <- aggregate(time ~ expr, out, median)[, 2] / 10^9
ylim <- range(o, 0); ylim[2] <- ylim[2] + .04 * diff(ylim)
plot(1:n_threads, o[-(1:2)], xlab = "Number of cores", yaxs = "i",
     ylim = ylim, ylab = "Run time", pch = 16)
abline(h = o[1], lty = 2)
abline(h = o[2], lty = 3)
abline(h = median(modmat_time$time) / 10^9, lty = 1)
```

It is worth mentioning that `speedglm` computes the cross product of the weighted design 
matrix. This is advantages in terms of computation cost but may lead to unstable 
solutions. You can alter the number of observations in each parallel chunk 
with the `block_size` argument of `parglm.control`.

The single threaded performance of `parglm` may be slower when there are more coefficients. 
The cause seems to be the difference between the LAPACK and LINPACK implementation. 
This presumably due to either the QR decomposition method and/or the `qr.qty` method. 
On Windows, the `parglm` do seems slower when build with `Rtools` and the reason 
seems so be the `qr.qty` method in LAPACK, `dormqr`, which is slower then the 
LINPACK method, `dqrsl`. Below is an illustration of the 
cost on this machine. 

```{r check_qr_qty, cache = 1}
qr1 <- qr(X)
qr2 <- qr(X, LAPACK = TRUE)
microbenchmark::microbenchmark(
  `qr LINPACK`     = qr(X), 
  `qr LAPACK`      = qr(X, LAPACK = TRUE), 
  `qr.qty LINPACK` = qr.qty(qr1, df$y), 
  `qr.qty LAPACK`  = qr.qty(qr2, df$y), 
  times = 5)
```

## Session info

```{r ses_info}
sessionInfo()
```

